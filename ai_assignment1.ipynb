{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQ7oXyr9zNqxuyXY8aijMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inwoo7233/AI_GITCT2020/blob/master/ai_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzT9HKklqFub",
        "colab_type": "text"
      },
      "source": [
        "# 인공지능 과제 1주차\n",
        "---\n",
        "## 1. 언어\n",
        "\n",
        "\n",
        "&nbsp;인공지능을 접목한 언어관련 서비스하면 가장 먼저 떠오르는 것이 번역 서비스입니다. 번역 서비스는 이미 우리에게 친숙한 서비스가 많이 있습니다. 아래 세 서비스는 구글에 '번역기'라는 이름으로 검색했을 때 상위에 표시되는 3가지 번역 서비스입니다.\n",
        "\n",
        "- 구글 번역기 (https://translate.google.co.kr/?hl=ko)\n",
        "- 파파고 (https://papago.naver.com/)\n",
        "- 카카오 번역 (https://translate.kakao.com/) \n",
        "\n",
        "\n",
        "&nbsp;기존의 번역기는 단순히 단어를 대조하여 바꿔주고, 약간의 알고리즘을 통해 문장을 자연스럽게 하는 기능이 전부였습니다. 따라서 'i love you' 같이 단순한 문장도 '나 너 사랑한다'와 같이 어색하게 번역되곤 했습니다. 하지만 요즘 번역기들은 모두 머신러닝 기술을 도입하였기 때문에 스스로 성능을 발전시킵니다.  직접써보면 정말 대단하다고 느껴질 정도로 문장이 자연스러워졌습니다. 'i love you' 정도야 쉽게 '사랑해'로 번역해내고, 이보다 훨씬 복잡한 'Use these projects to apply AI to cutting-edge work in healthcare.'같은 문장도 '\n",
        "이 프로젝트를 사용하여 AI를 첨단 의료 분야의 업무에 적용하십시오.'와 같이 꽤나 자연스럽게 번역해줍니다. \n",
        "\n",
        "\n",
        "&nbsp;저는 이중 **한국인에게 가장 친숙한 파파고**에 대해 알아보았습니다. 파파고는 네이버가 2016년 어플리케이션으로 처음 선보인 인공지능 기반의 번역기입니다. 현지인과 직접 대화하면서 사용가능한 1:1 대화모드, 카메라로 사진을 찍으면 이를 번역해주는 이미지번역, 환율 자동 변환 등 사용자가 실생활에서 사용하기 유용하도록 다양한 부가서비스를 제공합니다.\n",
        "\n",
        "&nbsp;이러한 파파고의 핵심은 Naver Labs에서 자체 개발한 인공신경망입니다. Naver Labs의 신경망만의 특징은 아마 해당 인공신경망을 연구한 연구진들만 알고 있을 것입니다. 하지만 일반적인 '번역기 인공신경망'의 특징을 이해한다면 파파고가 어떤 원리로 구동되고 발전해나가는지 이해할 수 있을 것입니다. \n",
        "\n",
        "&nbsp;인공신경망 기계번역에서는 번역할 문장이 입력되면 해당 문장을 벡터값으로 변환하고, 해당 벡터에 기계 학습을 통해 익힌 **'가중치'**를 더해 번역을 수행합니다. 인공신경망에서는 보통 **1000차원 이상의 벡터**를 사용합니다. 어떤 문장 입력이 이루어지면 1000차원의 공간의 한 점이 되고, 해당 점은 유사한 문장들과 가까운 곳에 위치하게 됩니다. 가령 'I love him'은 'He is by loved me'와 가까운 곳에 위치하는 것이지요. 이러한 위치정보 덕분에 인공신경망은 앞서 말한 비슷한 문장을 학습하고 번역해냅니다. 비슷한 원리로 'cat'과 'kitty'같은 유의어도 학습하고 번역할 수 있게 되죠.\n",
        "\n",
        "&nbsp;데이터 학습은 보통 **'병렬 코러스'**라고 불리는 '번역 문제(번역 전 문장)과 번역 정답(번역 후 문장)의 쌍'을 통해 이뤄집니다. 파파고는 이러한 병렬 코러스를 'GYM'이라는 서비스를 통해 사용자에게 직접 보여줍니다. 그리고 사용자가 해당 병렬 코러스의 문제와 정답이 올바르게 이어졌는지 확인하게 함으로서 파파고를 계속해서 학습시키고 번역의 정확도를 향상시키는 거지요. 물론 학습을 많이 도와준 사용자에게는 네이버 포인트같은 대가도 주어집니다.\n",
        "\n",
        "정보 출처 : \n",
        "- https://namu.wiki/w/%EB%84%A4%EC%9D%B4%EB%B2%84%20%ED%8C%8C%ED%8C%8C%EA%B3%A0?from=%ED%8C%8C%ED%8C%8C%EA%B3%A0\n",
        "- https://biz.chosun.com/site/data/html_dir/2016/11/08/2016110802495.html\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPzInVRRvzSB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " # 2. 음성\n",
        "\n",
        "\n",
        "&nbsp;음성 관련 AI서비스 중 우리에게 가장 친숙한 것은 인공지능 스피커가 아닐까 싶습니다. 인공지능 스피커는 우리의 음성을 인식하고 이를 분석하여 그에 맞는 서비스를 제공해줍니다. 다양한 회사에서 이러한 인공지능 스피커를 제작, 판매하고 있지만 먼저 떠오르는 3가지는 다음과 같습니다.\n",
        "- 구글 홈 (https://store.google.com/magazine/compare_nest_speakers_displays?srp=/product/google_home)\n",
        "- 네이버 클로바 (https://clova.ai/ko/ko-product-friends.html)\n",
        "- KT 기가지니 (https://gigagenie.kt.com/main.do)\n",
        "\n",
        "&nbsp;인공지능 스피커는 스마트 스피커라고도 불리며, 음성인식을 통해 음악재생, 정보 검색 등의 기능을 수행합니다. 단순히 음성인식을 하는 것을 넘어 인공지능을 통해 대화의 의도, 패턴을 학습합니다. \n",
        "\n",
        "&nbsp;인공지능 스피커는 \"음성 입력 및 인식 → 자연어 처리 → 인식 결과\"의 과정을 거칩니다. 먼저 음성 입력 및 인식, 즉 사람의 음성을 텍스트화합니다. 이러한 기술을 SST(Speech To Text)라고 합니다. 주변 소음을 제외한 말소리를 파악하고 각 발음과 단어를 인식해 핵심어와 연결단어를 인식, 입력합니다. 다음으로 자연어 처리(Natural Language Processing, NLP) 과정을 진행합니다. 자연어의 형태소, 구문, 의미 등을 분석해 컴퓨터가 이를 이해할 수 있도록 합니다. 마지막으로는 인식 결과를 내놓습니다. 인식된 요청에 따른 작업을 진행해 TTS(Text To Speech)기술로 사람의 말소리처럼 사용자의 요청을 처리합니다.\n",
        "\n",
        "&nbsp;이러한 인공지능 스피커는 딥러닝 기술로 크게 발전했습니다. 컴퓨터가 작업을 수행하는데 핵심적이라고 할 수 있는 자연어 처리 기술이 딥러닝 기술로 점점 발전하고 있는 것입니다. 현재 꽤 많은 발전으로 전보단 훨씬 정확히 우리들의 음성을 인식하지만, 아직 한계가 있습니다. 사람마다 발음과 억양, 톤이 다르고 문법에 어긋난 문장이 많이 사용되는 이유입니다. 이는 다양한 분야의 다양한 음성 데이터가 학습되면서 점점 극복될 것으로 보입니다.\n",
        "\n",
        "&nbsp;앞서 예시로 들었던 구글 홈, 네이버 클로바, KT 지니 중 하나를 찾아 실질적인 데이터를 조사하고자 했지만, 대부분 스펙이나 제공 서비스, 작동 환경 등에 대해서만 설명할 뿐 기술적인 내용은 적혀있지 않았습니다. 그도 그럴 것이 데이터 수집 및 처리 방식은 회사의 기밀적인 기술입니다. 자세히 알려줄리 만무합니다. 하지만 현재 이름이 알려진 IT 대기업 중 인공지능 스피커를 제작하지 않는 회사가 없습니다. 이는 곧 인공지능 스피커에 대한 사용자의 수요가 매우 많고, 인공지능 스피커가 회사의 데이터 수집, 인공지능 기술의 발전에 큰 도움을 준다는 증거가 아닐까 생각해봅니다.\n",
        "\n",
        "&nbsp;정보 출처:\n",
        "- https://ko.wikipedia.org/wiki/%EC%8A%A4%EB%A7%88%ED%8A%B8_%EC%8A%A4%ED%94%BC%EC%BB%A4\n",
        "- https://www.mobiinside.co.kr/2020/04/28/flitto-ai/\n",
        "- https://gigagenie.kt.com/main.do\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1OS-WD3w39u",
        "colab_type": "text"
      },
      "source": [
        "# 3. 이미지\n",
        "\n",
        "&nbsp;저는 이미지 관련 인공지능 서비스하면  구글의 Teachable Machine가 먼저 떠오릅니다. 이번학기에 해당 서비스로 프로젝트를 진행했기 때문입니다. 해당 서비스로 동전을 이미지 기반으로 인식하고 분류하는 모델을 만들어, '외화동전 분류기'를 제작했습니다. 텐서플로우에 대한 이해가 전혀 없는 상태였으나, 튜토리얼을 찾아보면서 모델을 제작하고 이를 활용할 수 있었습니다.\n",
        "\n",
        "- 구글 Teachable Machine 링크 : https://teachablemachine.withgoogle.com/\n",
        "- 외화 분류기 작동 링크 : https://youtu.be/4Dz5wEFGWz8\n",
        "\n",
        "&nbsp;사실 구글의 Teachable Machine은  이미지 분석만을 위한 서비스는 아닙니다. 음성을 기반으로 분류를 진행해주기도 하고, 포즈를 분석해 작동하기도 합니다. 하지만 어쨌든 저는 이 중 이미지 분석 서비스를 제공받아 사용했습니다. \n",
        "\n",
        "&nbsp;Teachable Machine은 개발자가 아닌 일반 사용자도 쉽게 사용할 수 있도록 제작되었기 때문에 사용법이 매우 간단합니다. 그저 분류할 대상의 사진 여러장을 분류별로 나눠서 찍고 업로드합니다. 그럼 Teachable Machine이 개발에도 사용할 수 있는 모델을 만들어줍니다.\n",
        "\n",
        "&nbsp;이러한 기술을 통해 사용자는 간단하게 분류 모델을 생성하고, 구글은 데이터 수집을 합니다. 구글이 데이터를 수집하기 위해 만들었다는 비평도 많지만, 저같이 인공지능에 대해 관심은 있지만 아직 기술적인 능력이 부족한 사람이 인공지능 기술을 체험해보는 정도의 목적으로는 좋은 서비스라고 생각합니다.\n",
        "\n",
        "&nbsp;정보 출처 :\n",
        "\n",
        "- https://teachablemachine.withgoogle.com/train\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2XoRuWbw-is",
        "colab_type": "text"
      },
      "source": [
        "# 4. 자율주행\n",
        "\n",
        "&nbsp;자율주행은 단순히 입력된 데이터를 기반으로 따라가거나, 인간이 설정한 알고리즘을 기반으로 진행되지 않습니다. 그렇게 했다간 도로 상황에서 벌어지는 여러 변수에 대처하기 힘들 것입니다. 따라서 자율주행에서도 딥러닝 기술을 이용해 제어 사물을 인식하고 장애물을 감지하는 능력을 키웁니다. 주로 이는 상향식 학습을 통해 이뤄집니다. 기초부터 어려운 것까지 단계적으로 학습하여 데이터를 축적하고 고도의 기능까지 구현해내는 것입니다.그 외에도 프로그래밍 하향식 기호 추론 기술까지 이용해 더 완전한 시스템을 만들어낸다고 합니다.\n",
        "\n",
        "&nbsp;자율주행 서비스는 Level0의 비자동에서부터 Level5의 완전 자동화까지 그 발전 단계를 나누는데, 현재는 Level3인 조건부 자동화에서 Level4인 고도 자동화로 넘어가는 상태라고 할 수 있습니다. 고도 자동화가 이루어진다면 핵심제어, 주행환경 모니터링, 비상시 대처 등 모두 인공지능 시스템이 수행합니다. 다만 항상 전적으로 시스템제어가 이뤄지는 것은 아닙니다.\n",
        "\n",
        "&nbsp;이러한 자율주행 기술은 구글, 제너럴 모터스, 아우디, 우버, 엔비디아, 애플, 테슬라 등 세계적인 기업뿐 아니라, 우리나라의 현대자동차에서도 개발 및 적용 중에 있습니다. 세계 기업에 비해 약간 뒤쳐지긴 했지만, 최근 서울에서 평창까지 도속도로에서 100km/h~110km/h를 유지하며 완전 자율주행에 성공하는 등 좋은 모습을 보여주고 있습니다.\n",
        "\n",
        "&nbsp;다양한 자율주행 서비스 중 가장 흥미로운 것은 comma.two라는 회사의 서비스였습니다. 사용자들의 기존 차량을 자율 주행차량으로 바꿀 수 있는 제품을 판매하는 회사입니다. 'openpilot'이라는 자율주행 소프트웨어를 MIT 라이센스로 공개배포하고 있다고 합니다. 이러한 기술을 통해 완전한 자율주행 자동차가 빠른 시일내에 상용화되고, 기존의 자동차도 comma.two의 제품으로 그 기술을 사용할 수 있을 것으로 보입니다. 인공지능 기술이 빠르게 발전하고 있기 때문에 이뤄낸 성과입니다.\n",
        "\n",
        "\n",
        "&nbsp;정보 출처 :\n",
        "\n",
        "- https://post.naver.com/viewer/postView.nhn?volumeNo=13598399&memberNo=6080211\n",
        "- https://namu.wiki/w/%EC%9E%90%EC%9C%A8%EC%A3%BC%ED%96%89%20%EC%9E%90%EB%8F%99%EC%B0%A8"
      ]
    }
  ]
}